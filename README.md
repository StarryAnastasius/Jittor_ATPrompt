# Jittor_ATPrompt
Jittor implementation of ATPrompt algorithm, with alignment verification against PyTorch version

æœ¬é¡¹ç›®æ˜¯å¯¹ICCV 2025è®ºæ–‡ã€ŠAdvancing Textual Prompt Learning with Anchored Attributesã€‹çš„å¤ç°ï¼Œä½¿ç”¨å›½äº§çš„Jittoræ·±åº¦å­¦ä¹ æ¡†æ¶å®ç°ã€‚

## ğŸ“– è®ºæ–‡ç®€ä»‹

**ATPrompt**çš„æ ¸å¿ƒæ€æƒ³æ˜¯

1. 
2. 
3. 

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
ğŸ“¦ atprompt/
â”œâ”€â”€ ğŸ“„ train.py             # è®­ç»ƒ/æµ‹è¯•å…¥å£è„šæœ¬
â”œâ”€â”€ ğŸ“„ convert_clip_weights.py  # CLIPæ¨¡å‹æƒé‡è½¬æ¢
â”œâ”€â”€ ğŸ“„ requirements.txt     # ä¾èµ–æ¸…å•
â”œâ”€â”€ ğŸ“„ README.md            # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ ğŸ“ datasets/            # æ•°æ®é›†å¤„ç†ï¼š
â”‚   â”œâ”€â”€ ğŸ“„ caltech101.py    # Caltech-101æ•°æ®é›†
â”‚   â”œâ”€â”€ ğŸ“„ dtd.py           # DTDæ•°æ®é›†
â”‚   â””â”€â”€ ğŸ“„ oxford_pets.py   # Oxford Petsæ•°æ®é›†
â”œâ”€â”€ ğŸ“ scripts/             # å¯ç›´æ¥è¿è¡Œçš„è®­ç»ƒæµ‹è¯•è„šæœ¬
â”œâ”€â”€ ğŸ“ trainers/            # è®­ç»ƒå™¨å®ç°ï¼š
â”‚   â”œâ”€â”€ ğŸ“„ coop.py          # åŸºç¡€COOP
â”‚   â””â”€â”€ ğŸ“„ coop_atp.py      # ATPrompt+COOP
â”œâ”€â”€ ğŸ“ clip/                # CLIPæ¨¡å‹åŠæ‰©å±•
â”œâ”€â”€ ğŸ“ configs/             # å®éªŒé…ç½®
â”œâ”€â”€ ğŸ“ interpret_prompts/   # Promptå¯è§£é‡Šæ€§åˆ†æ
â”œâ”€â”€ ğŸ“ Dassl.pytorch/       # åŸºäºJittorä¿®æ”¹çš„Dasslæ¡†æ¶
â””â”€â”€ ğŸ“ output/              # è¾“å‡ºç›®å½•
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

é¡¹ç›®ç¯å¢ƒé…ç½®ä¸ºï¼šubuntu2204ã€g++-11ã€jittor1.13.0

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt/
cd Dassl.pytorch/
pip install -r requirements.txt/
python setup.py develop
```

### 2. æ•°æ®å‡†å¤‡

ç¡®ä¿æ•°æ®é›†å·²ä¸‹è½½å¹¶æŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡ï¼š

```
root/prompt_dataset/
â”œâ”€â”€ caltech-101/
â”‚   â”œâ”€â”€ 101_ObjectCategories/
â”‚   â”‚   â”œâ”€â”€ accordion/
â”‚   â”‚   â”œâ”€â”€ airplanes/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ Annotations/
â””â”€â”€ dtd/
    â”œâ”€â”€ images/
    â”œâ”€â”€ labels/
    â””â”€â”€ imdb/

```


### 3. è¿è¡ŒCoOp+ATPè®­ç»ƒä¸å®éªŒ

```bash
bash scripts/coop/atp_base2new_train.sh caltech101
bash scripts/coop/atp_base2new_test.sh caltech101
bash scripts/coop/atp_base2new_train.sh dtd
bash scripts/coop/atp_base2new_test.sh dtd
```

## ğŸ”¬ å®éªŒè®¾ç½®

### ä»»åŠ¡åºåˆ—
- **ä»»åŠ¡1**: CUBS-200-2011 (é¸Ÿç±»åˆ†ç±»ï¼Œ200ä¸ªç±»åˆ«)
- **ä»»åŠ¡2**: Stanford Cars (æ±½è½¦åˆ†ç±»ï¼Œ196ä¸ªç±»åˆ«)  
- **ä»»åŠ¡3**: Oxford Flowers (èŠ±å‰åˆ†ç±»ï¼Œ102ä¸ªç±»åˆ«)

### å‰ªæç­–ç•¥
- **åˆå§‹å‰ªæ**: 75% (åœ¨ImageNeté¢„è®­ç»ƒæ¨¡å‹ä¸Š)
- **ä»»åŠ¡1å‰ªæ**: 75%
- **ä»»åŠ¡2å‰ªæ**: 75%  
- **ä»»åŠ¡3å‰ªæ**: 75%

### ç½‘ç»œæ¶æ„
- **åŸºç¡€æ¨¡å‹**: VGG-16 (ImageNeté¢„è®­ç»ƒ)
- **åˆ†ç±»å™¨**: ä¸ºæ¯ä¸ªä»»åŠ¡æ·»åŠ ç‹¬ç«‹çš„åˆ†ç±»å¤´

### âš ï¸ç®€åŒ–æµç¨‹
- ä¸ºäº†å¿«é€ŸéªŒè¯ï¼Œæš‚æ—¶æ²¡åœ¨ImageNetä¸Šé‡è®­ç»ƒï¼Œä¹Ÿæ²¡æœ‰å¯¹ImageNetçš„æ€§èƒ½è¿›è¡Œæµ‹è¯•

## ğŸ“Š æ ¸å¿ƒç®—æ³•

### 1. æ•°æ®é¢„å¤„ç† (`dataset.py`)

ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡ç¬¬4èŠ‚å®ç°ï¼š

- **CUBS & Cars**: ç›´æ¥ç¼©æ”¾åˆ°224Ã—224
- **Flowers**: çŸ­è¾¹ç¼©æ”¾åˆ°256ï¼Œç„¶å224Ã—224è£å‰ª
- **æ•°æ®å¢å¼º**: è®­ç»ƒæ—¶éšæœºæ°´å¹³ç¿»è½¬

```python
# åˆ›å»ºæ•°æ®åŠ è½½å™¨
train_loader, num_classes = create_dataloader(
    dataset_name='cubs',
    data_root='data',
    split='train',
    batch_size=32
)
```

### 2. PackNetå‰ªæç®—æ³• (`pruning.py`)

æ ¸å¿ƒå‰ªæå‡½æ•°å®ç°ï¼š

```python
# å¯¹æ¨¡å‹è¿›è¡Œå‰ªæ
new_mask = PackNetPruning.prune_model(
    model=model,
    pruning_ratio=0.75,  # å‰ªæ75%çš„æƒé‡
    previous_masks=previous_task_masks  # ä¿æŠ¤ä¹‹å‰ä»»åŠ¡çš„æƒé‡
)

# åº”ç”¨æ©ç å†»ç»“æƒé‡
PackNetPruning.freeze_weights_by_mask(model, previous_masks)
```

### 3. å¤šä»»åŠ¡è®­ç»ƒæµç¨‹ (`main.py`)

å®Œæ•´çš„PackNetè®­ç»ƒæµç¨‹ï¼š

1. **åˆå§‹å‰ªæ**: å¯¹VGG-16è¿›è¡Œ75%å‰ªæ
2. **ä»»åŠ¡å¾ªç¯**:
   - å†»ç»“ä¹‹å‰ä»»åŠ¡çš„æƒé‡
   - è®­ç»ƒå½“å‰ä»»åŠ¡
   - å‰ªæå½“å‰ä»»åŠ¡çš„æƒé‡
   - å¾®è°ƒæ¢å¤æ€§èƒ½
3. **æœ€ç»ˆè¯„ä¼°**: éªŒè¯æ‰€æœ‰ä»»åŠ¡çš„æ€§èƒ½ä¿æŒ

## ğŸ¯ å®éªŒç»“æœ


### Jittor å¤ç°ç»“æœ vs. è®ºæ–‡æŠ¥å‘Šç»“æœ (Top-1 å‡†ç¡®ç‡ %)

| **ä»»åŠ¡** | **Jittor å¤ç° (æœ¬é¡¹ç›®)** | PyTorchå¤ç° | **åŸè®ºæ–‡ (VGG-16, 75%å‰ªæ)** |
| :--- | :---: | :---: | ----- |
| CUBS | 68.69% | 75.94% | 75.05% (24.95% é”™è¯¯ç‡) |
| Stanford Cars | 79.14% | 83.39% | 84.25% (15.75% é”™è¯¯ç‡) |
| Flowers | 87.74% | 87.43% | 90.25% (9.75% é”™è¯¯ç‡) |

* ImageNetå‰ªæåæ²¡æœ‰è¿›è¡Œé‡è®­ç»ƒä½¿æ€§èƒ½æ¢å¤ã€‚ImageNetçš„å‚æ•°å¯¹åç»­ä»»åŠ¡éƒ½ä¼šç”¨åˆ°ï¼Œè¿™å¯èƒ½å½±å“æ€§èƒ½ã€‚
* æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸åŒã€‚

### è®­ç»ƒè¿‡ç¨‹ï¼ˆCUBSï¼‰

![image-20250714104323383](image-20250714104323383.png)

è®­ç»ƒå®Œæ•´logåœ¨log.txtä¸­ã€‚æ€»è®­ç»ƒæ—¶é•¿115minå·¦å³ã€‚

### ç¼“è§£ç¾éš¾æ€§é—å¿˜æ•ˆæœ

#### Jittor

![image-20250714104517345](image-20250714104517345.png)

#### PyTorchå¤ç°

![image-20250718155000567](image-20250718155000567.png)

## ğŸ”§ æ ¸å¿ƒç‰¹æ€§

### âœ… å·²å®ç°åŠŸèƒ½

1. **å®Œæ•´çš„æ•°æ®åŠ è½½å™¨**
   - æ”¯æŒä¸‰ä¸ªç»†ç²’åº¦åˆ†ç±»æ•°æ®é›†
   - æŒ‰ç…§è®ºæ–‡è¦æ±‚çš„é¢„å¤„ç†æ–¹æ³•
   - è‡ªåŠ¨ä»ç›®å½•ç»“æ„è§£ææ ‡ç­¾

2. **PackNetæ ¸å¿ƒç®—æ³•**
   - åŸºäºé‡è¦æ€§çš„æƒé‡å‰ªæ
   - æ©ç ç®¡ç†å’Œæƒé‡å†»ç»“
   - æ”¯æŒå¤šä»»åŠ¡è¿ç»­å­¦ä¹ 

3. **è®­ç»ƒå’Œè¯„ä¼°æ¡†æ¶**
   - å®Œæ•´çš„è®­ç»ƒå¾ªç¯
   - æ€§èƒ½è¯„ä¼°å’Œç»“æœä¿å­˜
   - æ¨¡å‹å’Œæ©ç æŒä¹…åŒ–

### ğŸ›ï¸ å¯é…ç½®å‚æ•°

```python
# Caltech101æ•°æ®é›†è®­ç»ƒé…ç½®


# DTDæ•°æ®é›†è®­ç»ƒé…ç½®  

```

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. **è®¡ç®—èµ„æº**: å®Œæ•´å®éªŒéœ€è¦GPUæ”¯æŒï¼Œå»ºè®®è‡³å°‘8GBæ˜¾å­˜
2. **æ•°æ®é›†å‡†å¤‡**: ç¡®ä¿æ•°æ®é›†ç›®å½•ç»“æ„æ­£ç¡®
3. **Jittorå®‰è£…**: éœ€è¦æ­£ç¡®å®‰è£…Jittoræ”¯æŒï¼ŒJittorçš„å®‰è£…éœ€è¦æŠ˜è…¾

âš ï¸å°è¯•åœ¨DCUä¸Šå®‰è£…Jittorå¹¶è®­ç»ƒï¼Œä½†å†…æ ¸æŠ¥é”™

## ğŸ“š å‚è€ƒæ–‡çŒ®

```bibtex
@article{li2024advancing,
  title={Advancing Textual Prompt Learning with Anchored Attributes},
  author={Li, Zheng and Song, Yibing and Cheng, Ming-Ming and Li, Xiang and Yang, Jian},
  journal={arXiv preprint arXiv:2412.09442},
  year={2024}
}
```
